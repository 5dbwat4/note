---
title: "Lab 1: ç®€å•é›†ç¾¤æ­å»º"
---

import Asciinema from '@/components/md-comp/AsciinemaWrapper.vue'
import Card from '@md-components/card.vue'

Update @ 2025-6-29 è¿œç¦»ä¸Šä¸–çºªè½»è–„æœ¬ï¼šæŠŠä¸¤ä¸ªä»»åŠ¡æŒªåˆ°äº†é˜¿é‡Œäº‘/HPC101èŠ‚ç‚¹ä¸Šï¼Œè‡³å°‘ä¸ç”¨æ‹…å¿ƒç”µè„‘å‘çƒ­äº†

# ä»»åŠ¡ä¸€ï¼šä»æºç æ„å»º OpenMPI å’Œ HPL

æºç æ„å»ºä¹Ÿæ˜¯ä¸å¾—ä¸åƒçš„ä¸€ç¯äº†

## OpenMPI

<Card title="ä»»åŠ¡" type="task">
- æ„å»ºå¹¶å®‰è£… OpenMPIï¼š
  - å‰å¾€ OpenMPI å®˜ç½‘ ä¸‹è½½æœ€æ–°ç‰ˆæœ¬æºç ã€‚
  - è§£å‹æºç ï¼Œè¿›å…¥æºç ç›®å½•ï¼Œé˜…è¯» README.mdã€‚
  - å‰å¾€åœ¨çº¿æ–‡æ¡£ï¼ŒæŸ¥çœ‹æ„å»ºå’Œå®‰è£…éƒ¨åˆ†ï¼ŒæŒ‰æ–‡æ¡£æŒ‡ç¤ºæ„å»ºå¹¶å®‰è£… OpenMPIã€‚
  - éªŒè¯å®‰è£…æ˜¯å¦æˆåŠŸã€‚æç¤ºï¼šè¿è¡Œ `ompi_info -all`ã€‚
</Card>

å‚è§ä»¥ä¸‹å½•å±ï¼š

import castCompileOpenMPI from "./casts/lab1-compile-from-code-OpenMPI.cast?url"

<Asciinema url={castCompileOpenMPI}/>

## BLASå’ŒCBLAS

<Card title="ä»»åŠ¡" type="task">
- æ„å»º BLASï¼ŒCBLASï¼š
  - ä¸‹è½½æŒ‡å®šç‰ˆæœ¬ BLAS æºç : blas-3.12.0.tgz, å¹¶å®Œæˆæ„å»ºã€‚
  - ä¸‹è½½æŒ‡å®šç‰ˆæœ¬ CBLAS æºç : CBLAS.tgzã€‚ç›¸åº”ä¿®æ”¹ `Makefile.in` åå®Œæˆæ„å»ºã€‚`æˆ‘ä»¬å¸Œæœ›ä½ èƒ½è§£å†³æ‰€æœ‰æŠ¥é”™ã€‚`
  - å¦‚æœæ²¡æœ‰é”™è¯¯ï¼Œä¸¤ä¸ªç›®å½•ä¸­éƒ½ä¼šç”Ÿæˆä¸€ä¸ª `.a` æ–‡ä»¶ï¼Œè¿™æ˜¯å¾…ä¼šè¦ç”¨åˆ°çš„é™æ€é“¾æ¥åº“ã€‚
</Card>

å‚è§ä»¥ä¸‹å½•å±ï¼š

import castCompileBlas from "./casts/lab1-code-compile-blas.cast?url"
import castCompileCblas from "./casts/lab1-code-compile-cblas.cast?url"

*BLAS*

<Asciinema url={castCompileBlas} />

*CBLAS*

<Asciinema url={castCompileCblas} />

## æ²¡æœ‰sudoå’‹åŠ

æ²¡æœ‰sudoçš„è¯æ˜¯æ²¡åŠæ³•`make install`åˆ°ç³»ç»Ÿçš„`/usr/local`ä¸‹çš„ï¼Œä½†æˆ‘ä»¬æœ‰é€€è€Œæ±‚å…¶æ¬¡çš„æ–¹æ¡ˆï¼š

åœ¨ç¼–è¯‘æ—¶æŒ‡æ˜`make prefix=$HOME/.local`å¯ä»¥å°†åº“å¼„åˆ°è‡ªå·±æœ‰æƒé™çš„ä½ç½®

è¿™æ ·çš„è¯åŠ¨æ€é“¾æ¥åº“ä»ä¸ä¼šæ›´æ–°ï¼ˆæ˜¾ç„¶æˆ‘ä»¬ä¹Ÿæ²¡åŠæ³•`sudo ldconfig`ï¼‰ï¼Œä½†æ˜¯å¯ä»¥ç”¨`export LD_LIBRARY_PATH=$HOME/.local/lib:$LD_LIBRARY_PATH`è§£å†³

import castSolveXhplLink from "./casts/lab1-solve-xhpl-lib-link.cast?url"

<Asciinema url={castSolveXhplLink} />


<center> *\*è§£å†³`xhpl`åŠ¨æ€é“¾æ¥åº“ç‚¸æ‰çš„é—®é¢˜\** </center>

æ­¤å¤–ï¼ŒOpenMPIå¯ä»¥è‡ªè¡Œç®¡ç†`PATH`å’Œ`LD_LIBRARY_PATH`ï¼Œæ‰€ä»¥åªè¦è¿è¡Œ`mpirun ./xhpl`èŠ‚ç‚¹ä¸ŠåŠ¨æ€é“¾æ¥åº“èƒ½ç”¨ï¼Œæ‰€æœ‰èŠ‚ç‚¹ä¸Šå°±éƒ½èƒ½ç”¨ (ref:[17.1.2. mpirun / mpiexec â€” Open MPI 5.0.x documentation](https://docs.open-mpi.org/en/v5.0.x/man-openmpi/man1/mpirun.1.html#remote-execution))

import TimeIcon from "@/assets/icons/mingcute~icon-line.vue"



<Card icon={TimeIcon} color="#88e4c2" title="è¿™ä¸€èŠ‚çš„åŸå§‹ç‰ˆæœ¬">

## ç¼–è¯‘OpenMPI

import cast1URL from "./casts/lab1-1.cast?url";

<Asciinema url={cast1URL} />

import cast2URL from "./casts/lab1-2.cast?url";

<Asciinema url={cast2URL} />

ç¼–è¯‘å¤§æˆåŠŸ

import cast9URL from "./casts/lab1-9.cast?url";

<Asciinema url={cast9URL} />

## ç¼–è¯‘BLASå’ŒCBLAS

import cast11URL from "./casts/lab1-11.cast?url";

<Asciinema url={cast11URL} />

ç¼–è¯‘BLASçš„è¿‡ç¨‹åŒæ ·æ˜¯ç•…é€šæ— é˜»

import cast12URL from "./casts/lab1-12.cast?url";

<Asciinema url={cast12URL} />

ç¼–è¯‘CBLASçš„è¿‡ç¨‹é‡åˆ°äº†`Rank mismatch in argument â€˜strue1â€™ at (1) (scalar and rank-1)`ï¼Œå°æ”¹ä¸€ä¸‹`FFLAGS`(è§†é¢‘4:07å¤„)å°±è¿‡äº†ï¼Œæ•´ä½“ä¸Šä»ç„¶ç•…é€šæ— é˜»


## ç¼–è¯‘HPL

import cast6URL from "./casts/lab1-6.cast?url";

<Asciinema url={cast6URL} />

è¯¥å½•å±ä¸­å±•ç¤ºäº†æˆ‘ä»¬ä»å¿˜æ”¹g99ä¸€ç›´åˆ°æœ€ç»ˆç¼–è¯‘æˆåŠŸçš„è¿‡ç¨‹ï¼ˆè™½ç„¶ç»“å°¾çš„xhplè¿è¡ŒæŠ¥é”™äº† ~~ï¼ˆåºŸè¯dockerè¿˜æ²¡é…å‘¢èƒ½è¿è¡Œèµ·æ¥å°±æœ‰é¬¼äº†ï¼‰~~ ï¼‰

</Card>

# ä»»åŠ¡äºŒï¼šæ­å»ºé›†ç¾¤å¹¶ä½¿ç”¨ HPL æµ‹è¯•æ€§èƒ½

<Card title="å…³äºè¿è¡Œç¯å¢ƒçš„è¯´æ˜" type="info">

æˆ‘ä»¬çš„ *æ­å»ºé›†ç¾¤* å’Œ *HPL æ€§èƒ½è°ƒä¼˜* ä¸åœ¨åŒä¸€ä¸ªç¯å¢ƒä¸‹ ï¼ˆZen2çš„CPUè·‘è¿™ç©æ„å¯ä¸æ˜¯è·Ÿä½ é—¹ç€ç©çš„ï¼‰

- ä½¿ç”¨dockeråœ¨æœ¬æœºæ„å»ºäº†ä¸€ä¸ªå…·æœ‰4ä¸ªèŠ‚ç‚¹çš„é›†ç¾¤ï¼Œå®ç°äº†ä¸€ç›´åˆ° *è°ƒæ•´ HPL.dat å‚æ•°ä¼˜åŒ–æ€§èƒ½* å¾€å‰çš„å·¥ä½œï¼Œè¯¥é›†ç¾¤æ»¡è¶³ï¼š
  - è‡³å°‘æœ‰ 4 ä¸ªåœ¨çº¿èŠ‚ç‚¹ã€‚
  - èŠ‚ç‚¹ä¹‹é—´èƒ½å¤Ÿé€šè¿‡ ssh è¿›è¡Œäº’è”ã€‚MPI èƒ½æ­£å¸¸å·¥ä½œã€‚
- ä½¿ç”¨HPC101çš„è®¡ç®—èŠ‚ç‚¹å®Œæˆäº† *è°ƒæ•´ HPL.dat å‚æ•°ä¼˜åŒ–æ€§èƒ½* çš„å·¥ä½œ

</Card>


## é…ç½®é›†ç¾¤ï¼

<Card type="task" title="ä»»åŠ¡">

- åˆ›å»º Dockerfileï¼š
  - å®‰è£…å¿…è¦çš„ä¾èµ–åŒ…å’Œç¼–è¯‘å·¥å…·
  - é…ç½® SSH æœåŠ¡ç”¨äºå®¹å™¨é—´é€šä¿¡
  - é…ç½® SSH å¯†é’¥è®¤è¯
  - åŸºäº Linux é•œåƒåˆ›å»ºåŒ…å«ç¼–è¯‘å®‰è£… MPI å’Œ HPL çš„ Dockerfile
- æ„å»ºå’Œè¿è¡Œå®¹å™¨ï¼š
  - ä½¿ç”¨ docker-compose åˆ›å»ºå¤šä¸ªå®¹å™¨å®ä¾‹
  - é…ç½®å®¹å™¨ç½‘ç»œå®ç°äº’è”
  - è®¾ç½®å®¹å™¨ä¸»æœºåå’Œ hosts æ–‡ä»¶
- è¿è¡Œ HPL æµ‹è¯•ï¼š
  - åœ¨å®¹å™¨ä¸­é…ç½® hostfile
  - ä½¿ç”¨ mpirun è¿è¡Œ HPL æµ‹è¯•

</Card>


```dockerfile
FROM dockerhub.zjusct.io/library/ubuntu:25.10 AS build
# å®‰è£…ä¾èµ–
RUN apt-get update  && DEBIAN_FRONTEND=noninteractive apt-get install --no-install-recommends -y \
    build-essential \
    wget \
    openssh-server \
    openmpi-bin \
    libopenmpi-dev \
    libopenblas-dev \
        iputils-ping \
    net-tools \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£… HPL
WORKDIR /opt
COPY ./hpl-2.3.tar.gz .
RUN tar xvf hpl-2.3.tar.gz && rm hpl-2.3.tar.gz

# ç¼–è¯‘ HPL
WORKDIR /opt/hpl-2.3
RUN ./configure --prefix=/usr/local/hpl LDFLAGS="-lm" LIBS="-lm" 
RUN make && make install

# æ–°ç”¨æˆ·
RUN useradd -m hpl && echo "hpl:hpl" | chpasswd
RUN chown -R hpl:hpl /usr/local/hpl

# åˆ›å»ºå·¥ä½œç›®å½•
WORKDIR /home/hpl
COPY entrypoint.sh .
RUN chmod +x entrypoint.sh #entrypointå°†ä¼šå¤„ç†sshæœåŠ¡

COPY ./ssh /home/hpl/.ssh
RUN chmod 700 /home/hpl/.ssh && chmod 600 /home/hpl/.ssh/* && chown -R hpl:hpl /home/hpl/.ssh

EXPOSE 22
ENTRYPOINT ["./entrypoint.sh"]
```

å½“ç„¶è¿˜æœ‰æˆ‘ä»¬çš„`docker-compose.yml`æ–‡ä»¶ï¼š

```yaml
version: '3'
services:
  node01:
    image: ${APPLIED_IMAGE}
    hostname: node01
    environment:
      - HOSTS=${HOSTS} 
    networks:
      hpl_net:
        ipv4_address: 172.20.0.2

  node02:
    image: ${APPLIED_IMAGE}
    hostname: node02
    environment:
      - HOSTS=${HOSTS} 
    networks:
      hpl_net:
        ipv4_address: 172.20.0.3

  node03:
    image: ${APPLIED_IMAGE}
    hostname: node03
    environment:
      - HOSTS=${HOSTS} 
    networks:
      hpl_net:
        ipv4_address: 172.20.0.4

  node04:
    image: ${APPLIED_IMAGE}
    hostname: node04
    environment:
      - HOSTS=${HOSTS} 
    networks:
      hpl_net:
        ipv4_address: 172.20.0.5

networks:
  hpl_net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
```

æŒ‰ç…§å®éªŒæ–‡æ¡£ç»™çš„æ–¹æ¡ˆï¼Œæ¯ä¸ªnodeéƒ½æ˜¯`build: .`~~è™½ç„¶æˆ‘ä»¬çŸ¥é“dockeræœ‰å±‚ç¼“å­˜ä¸ä¼šæ¯æ¬¡éƒ½é‡æ–°ç¼–è¯‘ï¼Œä½†å¯åŠ¨çš„æ—¶å€™è¿˜æ˜¯è†ˆåº”çš„æ…Œ~~ï¼Œæ€»ä¹‹æˆ‘ä»¬å…ˆ`docker build -t "5dbwat4/hpc101-lab1-hpl-openblas:1.0" . `ï¼ˆè€Œä¸”å¯¼å‡ºå’Œåˆ†äº«ä¹Ÿæ–¹ä¾¿ï¼‰ï¼Œåå­—é…ç½®åˆ°`.env`é‡Œé¢ï¼Œç„¶åå†`docker-compose up -d`ã€‚

import cast14URL from "./casts/lab1-14.cast?url";

<Asciinema url={cast14URL} />

å½“ç„¶è¿˜æœ‰æˆ‘ä»¬ä¸å¾—ä¸æçš„æƒé™é—®é¢˜ï¼ˆä¸€å¼€å§‹å¿˜äº†ç»™`/home/hpl/.ssh`ç»™æƒé™äº† ~~ï¼ˆç›¸å…³ç‰‡æ®µå·²è£å‰ªï¼ˆå…¶å®ä¸Šé¢é‚£ä¸ªå½•å±çš„åç»­å°±æ˜¯`ssh node02`ä»¥åŠ`cannot open directory '.ssh': Permission denied`ï¼‰ï¼‰~~ ï¼‰



import cast15URL from "./casts/lab1-15.cast?url";

<Asciinema url={cast15URL} />

æµ‹è¯•è¿é€šæ€§ï¼è™½ç„¶è¿‡ç¨‹ä¸å¤ªé¡ºåˆ©ï¼Œä½†è¿˜æ˜¯æˆåŠŸäº†

import cast16URL from "./casts/lab1-16.cast?url";

<Asciinema url={cast16URL} />

åœ¨è™šæ‹Ÿæœºé›†ç¾¤ä¸Šä½¿ç”¨ OpenMPI è¿è¡Œ HPL æ€§èƒ½æµ‹è¯•


## æ€§èƒ½è°ƒä¼˜

<Card title="ä»»åŠ¡" type="task">

åœ¨å®ŒæˆåŸºæœ¬çš„ HPL æµ‹è¯•åï¼Œä½ å¯ä»¥å°è¯•é€šè¿‡ä»¥ä¸‹æ–¹æ³•æé«˜æ€§èƒ½ï¼š

1. è°ƒæ•´ HPL.dat å‚æ•°ï¼š
   - è°ƒæ•´é—®é¢˜è§„æ¨¡ N ä»¥å……åˆ†åˆ©ç”¨å†…å­˜
   - è°ƒæ•´åˆ†å—å¤§å° NB ä»¥ä¼˜åŒ–è®¡ç®—æ•ˆç‡
   - è°ƒæ•´ PÃ—Q è¿›ç¨‹ç½‘æ ¼å¸ƒå±€ä»¥åŒ¹é…é›†ç¾¤æ‹“æ‰‘
2. ç¼–è¯‘ä¼˜åŒ–ï¼š
   - æ›´æ¢ç¼–è¯‘å™¨
   - ä¿®æ”¹ç¼–è¯‘ä¼˜åŒ–é€‰é¡¹
   - å°è¯•æ›´æ¢ BLAS åº“
3. è¿è¡Œç¯å¢ƒä¼˜åŒ–ï¼š
   - ä¼˜åŒ– OpenMP ç»‘æ ¸å‚æ•°
   - è°ƒæ•´ MPI è¿›ç¨‹ç»‘å®šï¼Œrank æ‹“æ‰‘

è¯·è®°å½•ä½ å°è¯•è¿‡çš„ä¼˜åŒ–æ–¹æ³•åŠå…¶æ•ˆæœï¼Œåˆ†ææ€§èƒ½æå‡çš„åŸå› ã€‚æ€§èƒ½çš„ç»å¯¹å€¼ä¸ä½œä¸ºè¯„åˆ¤ä¾æ®ï¼Œé‡è¦çš„æ˜¯ä½ é€šè¿‡å“ªäº›æ–¹æ³•æé«˜äº†æ€§èƒ½ï¼Œä»¥åŠä½ å¯¹è¿™äº›ä¼˜åŒ–æ–¹æ³•çš„ç†è§£ã€‚
</Card>

### è°ƒæ•´ HPL.dat å‚æ•°

ref: [HPL Tuning](https://www.netlib.org/benchmark/hpl/tuning.html)

ref: [HPL Frequently Asked Questions](https://www.netlib.org/benchmark/hpl/faqs.html)

æµ‹äº†ä¸€äº›æ•°æ®

```plain
================================================================================
T/V                N    NB     P     Q               Time                 Gflops
--------------------------------------------------------------------------------
WR00R2C4        5120    32     4     4               1.99             4.4937e+01

================================================================================
T/V                N    NB     P     Q               Time                 Gflops
--------------------------------------------------------------------------------
WR00R2C4       10240    32     4     4              15.43             4.6394e+01

================================================================================
T/V                N    NB     P     Q               Time                 Gflops
--------------------------------------------------------------------------------
WR00R2C8       10240    48     4     4              15.35             4.6653e+01

================================================================================
T/V                N    NB     P     Q               Time                 Gflops
--------------------------------------------------------------------------------
WR00R2C8       10240    48     1    16              23.67             3.0244e+01

================================================================================
T/V                N    NB     P     Q               Time                 Gflops
--------------------------------------------------------------------------------
WR00R2C4       20480    32     4     4             126.13             4.5409e+01

```

å¾—å‡ºå¤§è‡´åœ¨`N=10240`ï¼Œ`NB=48`ï¼Œ`P=4`ï¼Œ`Q=4`æ—¶æ€§èƒ½è¾ƒå¥½

p.s. äº¤çš„HPL.outæ˜¯åç»­ç”¨OpenBLASè°ƒä¼˜ä¹‹åæµ‹çš„ï¼Œæµ‹å‡ºæ¥æœ€å¥½çš„é…ç½®æ˜¯ï¼š
```plain
================================================================================
T/V                N    NB     P     Q               Time                 Gflops
--------------------------------------------------------------------------------
WR00R2R2       10240    96     2     8               1.50             4.7675e+02
```

**å¯¹ä¼˜åŒ–æ–¹æ³•çš„ç†è§£**ï¼š

**1. è°ƒæ•´é—®é¢˜è§„æ¨¡ N ä»¥å……åˆ†åˆ©ç”¨å†…å­˜**

ä¸ºäº†æ‰¾å‡ºç³»ç»Ÿçš„æœ€ä½³æ€§èƒ½ï¼Œåº”è¯¥é€‰æ‹©é€‚åˆå†…å­˜çš„æœ€å¤§é—®é¢˜è§„æ¨¡ã€‚å¦‚æœé€‰æ‹©çš„é—®é¢˜è§„æ¨¡è¿‡å¤§ï¼Œå°±ä¼šå‘ç”Ÿäº¤æ¢ï¼Œæ€§èƒ½ä¼šä¸‹é™ã€‚

é€šå¸¸æ¥è¯´ï¼Œåº”è¯¥é€‰æ‹©æ€»å†…å­˜çš„80%ä½œä¸ºé—®é¢˜è§„æ¨¡çš„ä¸Šé™ã€‚

> In order to find out the best performance of your system, the largest problem size fitting in memory is what you should aim for. The amount of memory used by HPL is essentially the size of the coefficient matrix. So for example, if you have 4 nodes with 256 Mb of memory on each, this corresponds to 1 Gb total, i.e., 125 M double precision (8 bytes) elements. The square root of that number is 11585. One definitely needs to leave some memory for the OS as well as for other things, so a problem size of 10000 is likely to fit. As a rule of thumb, 80 % of the total amount of memory is a good guess. If the problem size you pick is too large, swapping will occur, and the performance will drop. If multiple processes are spawn on each node (say you have 2 processors per node), what counts is the available amount of memory to each process. ([ref](https://www.netlib.org/benchmark/hpl/faqs.html#pbsize))

**2. è°ƒæ•´åˆ†å—å¤§å° $NB$ ä»¥ä¼˜åŒ–è®¡ç®—æ•ˆç‡**  

NBæ˜¯HPLä¸­æ•°æ®åˆ†å¸ƒå’Œè®¡ç®—ç²’åº¦çš„å…³é”®å‚æ•°ã€‚è¿‡å°ä¼šå¯¼è‡´è®¡ç®—æ€§èƒ½å—é™ï¼ˆå†…å­˜å±‚æ¬¡ç»“æ„æ— æ•°æ®é‡ç”¨ï¼‰ï¼Œæ¶ˆæ¯æ•°é‡ä¹Ÿä¼šå¢åŠ ï¼›è¿‡å¤§åˆ™ä¼šå½±å“è´Ÿè½½å‡è¡¡çš„æ•ˆæœã€‚

> HPL uses the block size NB for the data distribution as well as for the computational granularity. From a data distribution point of view, the smallest NB, the better the load balance. You definitely want to stay away from very large values of NB. From a computation point of view, a too small value of NB may limit the computational performance by a large factor because almost no data reuse will occur in the highest level of the memory hierarchy. The number of messages will also increase. Efficient matrix-multiply routines are often internally blocked. Small multiples of this blocking factor are likely to be good block sizes for HPL. The bottom line is that "good" block sizes are almost always in the [32 .. 256] interval. The best values depend on the computation / communication performance ratio of your system. To a much less extent, the problem size matters as well. Say for example, you emperically found that 44 was a good block size with respect to performance. 88 or 132 are likely to give slightly better results for large problem sizes because of a slighlty higher flop rate.([ref](https://www.netlib.org/benchmark/hpl/faqs.html#blsize))


**3. è°ƒæ•´ PxQ è¿›ç¨‹ç½‘æ ¼å¸ƒå±€ä»¥åŒ¹é…é›†ç¾¤æ‹“æ‰‘**


è¿›ç¨‹ç½‘æ ¼çš„ PxQ æ¯”ä¾‹ç›´æ¥å½±å“é€šä¿¡æ•ˆç‡ã€‚P å’Œ Q åº”è¯¥å¤§è‡´ç›¸ç­‰ï¼ŒQ ç•¥å¤§äº Pã€‚ï¼ˆé™¤äº†4x4çš„å¸ƒå±€ï¼Œä¹Ÿå°è¯•äº†1x16çš„æç«¯å¸ƒå±€ï¼Œå¯ä»¥æ˜¾è‘—çœ‹å‡ºæ€§èƒ½çš„ä¸‹é™ï¼‰
> This depends on the physical interconnection network you have. Assuming a mesh or a switch HPL "likes" a 1:k ratio with k in [1..3]. In other words, P and Q should be approximately equal, with Q slightly larger than P. Examples: 2 x 2, 2 x 4, 2 x 5, 3 x 4, 4 x 4, 4 x 6, 5 x 6, 4 x 8 ... If you are running on a simple Ethernet network, there is only one wire through which all the messages are exchanged. On such a network, the performance and scalability of HPL is strongly limited and very flat process grids are likely to be the best choices: 1 x 4, 1 x 8, 2 x 4 ... (  [ref](https://www.netlib.org/benchmark/hpl/faqs.html#grid) )


### å°è¯•æ›´æ¢ BLAS åº“

æ¢ç”¨OpenBLASç¼–è¯‘HPL

ç»“æœæ˜¯ï¼šè¿è¡Œé€Ÿåº¦å¿«å¤šäº†ï¼Œè·‘å‡ºæ¥çš„Gflopsæ›´æ˜¯ç›´æ¥ä¸Šäº†ä¸ªæ•°é‡çº§

```plain
================================================================================
T/V                N    NB     P     Q               Time                 Gflops
--------------------------------------------------------------------------------
WR00R2C8       10240    48     4     4               1.94             3.6896e+02

================================================================================
T/V                N    NB     P     Q               Time                 Gflops
--------------------------------------------------------------------------------
WR00R2C8       20480    48     4     4              13.31             4.3040e+02
```

# Bonusä»»åŠ¡

## é€šè¿‡ NFS æˆ–å…¶ä»–å…±äº«æ–‡ä»¶ç³»ç»Ÿï¼Œå®ç°é›†ç¾¤é—´æ–‡ä»¶å…±äº«

å¯¹äºdockerï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`volumes`æ¥å®ç°é›†ç¾¤é—´æ–‡ä»¶å…±äº«

```yaml
version: '3'
services:
  node01:
    image: ${APPLIED_IMAGE}
    hostname: node01
    environment:
      - HOSTS=${HOSTS} 
    networks:
      hpl_net:
        ipv4_address: 172.20.0.2
    volumes:
      - ./hpl_data:/home/hpl/data
  node02:
    ...
    volumes:
      - ./hpl_data:/home/hpl/data


```

ä½¿ç”¨volumeså°†æœ¬æœºä¸Šçš„`./hpl_data`ç›®å½•æŒ‚è½½åˆ°æ¯ä¸ªèŠ‚ç‚¹çš„`/home/hpl/data`ç›®å½•ä¸‹

ref: [Volumes | Docker Docs](https://docs.docker.com/engine/storage/volumes/)


## (*)é€‰æ‹©ä½ å–œæ¬¢çš„èŠ‚ç‚¹æŒ‡æ ‡ï¼Œæ—¥å¿—æ”¶é›†ï¼Œç›‘æ§ç­‰æ–¹æ³•ï¼Œå¹¶åˆ©ç”¨ grafana ç­‰å·¥å…·è¿›è¡Œå¯è§†åŒ–

<Card type="info" title="Note ğŸ‘‰ğŸ‘ˆ">
è¿™ä¸ªä»»åŠ¡æ˜¯åœ¨hpc101é›†ç¾¤ä¸Šå®Œæˆçš„
</Card>

æˆ‘ä»¬å°†ä½¿ç”¨**Prometheus**+**Grafana**å®ç°è¯¥ä»»åŠ¡

### Step 1: å®‰è£…ç›¸å…³å·¥å…·

å‚è€ƒ[First steps with Prometheus | Prometheus](https://prometheus.io/docs/introduction/first_steps/)å‰å¾€[Download | Prometheus](https://prometheus.io/download/)ä¸‹è½½prometheuså’Œnode_exporter

å‚è€ƒ[Install Grafana on Debian or Ubuntu | Grafana documentation](https://grafana.com/docs/grafana/latest/setup-grafana/installation/debian/)ä¸‹è½½grafana

ç”±äºæ²¡æœ‰sudoï¼Œæ‰€ä»¥éƒ½æ˜¯ä½¿ç”¨ä¸‹è½½é¢„ç¼–è¯‘äºŒè¿›åˆ¶æ–‡ä»¶çš„æ–¹å¼

### Step 2: é…ç½®Prometheus

å…ˆsshåˆ°æ¯ä¸ªèŠ‚ç‚¹è¿è¡Œä¸€ä¸‹`node_exporter`

ç„¶åå›åˆ°Prometheusï¼Œé…ç½®prometheus.ymlï¼Œä¿®æ”¹é»˜è®¤çš„scrape_configsä¸ºå¦‚ä¸‹å†…å®¹

```yaml
# A scrape configuration containing exactly one endpoint to scrape:
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: "prometheus"
    static_configs:
      - targets:  
          - "M600:9100" 
          - "M601:9100"
          - "M602:9100"
          - "M603:9100"
```

æˆ‘ä»¬æ‰“ç®—ç›‘å¬å››ä¸ªèŠ‚ç‚¹ï¼Œå°±é…ç½®è¿™å››ä¸ªèŠ‚ç‚¹ï¼Œ9100æ˜¯node_exporteræš´éœ²çš„ç«¯å£

é…å®Œå°±ç›´æ¥è¿è¡Œ`./prometheus --config.file=prometheus.yml`

import castRunPrometheus from './casts/lab1-run-prometheus.cast?raw'

<Asciinema cast={castRunPrometheus} />

ref: [First steps with Prometheus | Prometheus](https://prometheus.io/docs/introduction/first_steps/)

### Step 3: é…ç½®Grafana

ç›´æ¥è¿è¡Œ`grafana server`ç„¶åå‰©ä¸‹çš„å°±åˆ°æµè§ˆå™¨é‡Œæ“ä½œäº†

import castRunGrafana from './casts/lab1-run-grafana.cast?raw'

<Asciinema cast={castRunGrafana} />

ref: [Grafana support for Prometheus | Prometheus](https://prometheus.io/docs/visualization/grafana/)

å…³äº *é€‰æ‹©ä½ å–œæ¬¢çš„èŠ‚ç‚¹æŒ‡æ ‡* è¿™ä¸ªéƒ¨åˆ†ï¼Œæˆ‘ä»¬ç›´æ¥å·äº†ä¸€ä¸ªç°æˆè¿˜ä¸ç®—éš¾çœ‹çš„dashboardé…ç½® [Node Exporter Full | Grafana Labs](https://grafana.com/grafana/dashboards/1860-node-exporter-full/)

![æ­¤æ—¶æœ‰äººåœ¨ç”¨xhplç‚¸èŠ‚ç‚¹](./assets/lab1-pr-1.png)

<center> *\*æ­¤æ—¶æœ‰äººåœ¨ç”¨xhplç‚¸èŠ‚ç‚¹ï¼ˆx\** </center>

